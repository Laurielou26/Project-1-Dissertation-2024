#Load libraries 

library(tidyverse)
library(caret) 
library(Rcpp)
library(plotly)
library(ggfortify)
library(kknn)
library(reshape2)
library(Rcpp)
library(doParallel)
library(survival)
library(survminer)
library(plotROC)

#data being used (change to relevant file path)
methylation_data<- read.delim("C:/Users/lauri/OneDrive - Queen's University Belfast/Master's/Dissertation/Dissertation/Dataset/Lung/lusc_tcga_pan_can_atlas_2018/data_methylation_hm27_hm450_merged.txt")
merged_data_df_K #From previous analysis, will be in environment

methylation <- methylation_data

#remove metastatic samples

head(methylation)

# Remove rows with NA values and unnecessary columns 
methylation <- methylation[complete.cases(methylation[, -(1:4)]), ]


# Metastatic samples identified, see Step 1
metastatic_samples <- c("TCGA-18-3414", "TCGA-18-3417", "TCGA-33-4587", "TCGA-33-6738", 
                        "TCGA-33-A4WN", "TCGA-33-A5GW", "TCGA-33-AAS8", "TCGA-33-AASB", 
                        "TCGA-33-AASD", "TCGA-33-AASI", "TCGA-33-AASJ", "TCGA-33-AASL", 
                        "TCGA-34-8455", "TCGA-37-4132", "TCGA-43-6647", "TCGA-43-6770", 
                        "TCGA-43-6771", "TCGA-43-6773", "TCGA-43-7656", "TCGA-43-7657", 
                        "TCGA-43-8115", "TCGA-43-A56U", "TCGA-56-5897", "TCGA-56-6546", 
                        "TCGA-56-7223", "TCGA-56-7731", "TCGA-56-8082", "TCGA-56-8083", 
                        "TCGA-56-8201", "TCGA-56-8304", "TCGA-56-8308", "TCGA-56-8309", 
                        "TCGA-56-8504", "TCGA-56-8623", "TCGA-56-8624", "TCGA-56-8625", 
                        "TCGA-56-8626", "TCGA-56-8628", "TCGA-56-8629", "TCGA-56-A49D", 
                        "TCGA-56-A4BX", "TCGA-56-A4BY", "TCGA-56-A5DR", "TCGA-56-A5DS", 
                        "TCGA-56-A62T", "TCGA-58-8386", "TCGA-60-2709", "TCGA-66-2742", 
                        "TCGA-68-7756", "TCGA-68-7757", "TCGA-68-8250", "TCGA-68-A59J", 
                        "TCGA-6A-AB49", "TCGA-90-6837", "TCGA-90-7766", "TCGA-90-7767", 
                        "TCGA-90-7769", "TCGA-90-7964", "TCGA-90-A4ED", "TCGA-90-A4EE", 
                        "TCGA-90-A59Q", "TCGA-92-7340", "TCGA-92-7341", "TCGA-92-8063", 
                        "TCGA-92-8064", "TCGA-92-8065", "TCGA-94-7033", "TCGA-94-7943", 
                        "TCGA-94-8035", "TCGA-94-A5I4", "TCGA-96-7544", "TCGA-96-7545", 
                        "TCGA-J1-A4AH", "TCGA-LA-A446", "TCGA-LA-A7SW", "TCGA-MF-A522", 
                        "TCGA-NC-A5HF", "TCGA-NC-A5HP", "TCGA-NK-A5CR", "TCGA-NK-A5CX", 
                        "TCGA-O2-A52N", "TCGA-O2-A52Q", "TCGA-O2-A52S", "TCGA-O2-A52V", 
                        "TCGA-O2-A52W", "TCGA-O2-A5IB")

# Convert patient IDs to match the column names in the methylation data
metastatic_columns <- paste0(gsub("-", ".", metastatic_samples), ".01")

# Check if these columns exist in the methylation dataframe
metastatic_columns <- metastatic_columns[metastatic_columns %in% colnames(methylation)]

# Remove metastatic samples from RNA-seq data
filtered_meta_methyl <- methylation %>% select(-all_of(metastatic_columns))

# Remove metastatic samples from RNA-seq data
filtered_meta_data_reset_methyl <- methylation %>% select(-all_of(metastatic_columns))

#ML model training attempt 

# Transpose the dataframe
methyl_df <- as.data.frame(t(filtered_meta_methyl))

# Make the first row as header
colnames(methyl_df) <- methyl_df[2,]

# Remove the first four row from df
methyl_df <- methyl_df[-1, ] # 4 times 
methyl_df <- methyl_df[-1, ]
methyl_df <- methyl_df[-1, ]
methyl_df <- methyl_df[-1, ]

# Reset row names to NULL
rownames(methyl_df) <- NULL

methyl_df <- t(methyl_df)

rownames_original <- rownames(methyl_df)

# Step 2: Convert the data to numeric (by converting the entire matrix)
methyl_df_numeric <- apply(methyl_df, 2, as.numeric)

# Step 3: Reassign the row names
rownames(methyl_df_numeric) <- rownames_original

# Check the structure of the new data frame
str(methyl_df_numeric)

# Convert the numeric matrix back to a data frame
methyl_df_numeric_df <- as.data.frame(methyl_df_numeric)

#add a new with median expression per gene 
methyl_df_numeric_df$med <- apply(methyl_df_numeric_df ,1 ,median)

# Calculate variance while removing NAs, 2 means function is applied to
methyl_df_numeric_df$var <- apply(methyl_df_numeric_df, 1, var)

# Filter based on variance threshold
methyl_filtered <- methyl_df_numeric_df %>% filter( med >= quantile(med,c(0.5, 0.9), na.rm =FALSE) & var >= quantile (var, c(0.5,0.9), na.rm =TRUE)) 

#remove the var and med columns 
methyl_filtered <- methyl_filtered[1:(ncol(methyl_filtered)-2)]

# View the filtered data
head(methyl_filtered)

methyl_filtered <- t(methyl_filtered)
methyl_filtered <- as.data.frame(methyl_filtered)

# Add Sample_id column with sample identifiers
methyl_filtered$Sample_ID <- colnames(filtered_meta_methyl) [-c(1, 2, 3, 4)] 

#View the merged data frame
head(methyl_filtered[1:5]) 

# Merge with sample_clusters_k6 by "Sample_ID"
merged_df <- merge(methyl_filtered, sample_clusters_k, by = "Sample_ID")



# Ensure all data (except the Sample_ID column) is numeric
numeric_columns <- lapply(merged_df[,-1], as.numeric)
numeric_df <- as.data.frame(numeric_columns)
numeric_df$Sample_ID <- merged_df$Sample_ID

str(numeric_df$Sample_ID)

#remove NAs
numeric_df <- na.omit(numeric_df)

#make cluster a factor 

numeric_df$Cluster <- as.factor(numeric_df$Cluster)


#now need to remove highly correlated genes 


ngenes <- ncol(numeric_df)-2

correlationMatrix <- cor(numeric_df[1:ngenes])

highlyCorrelated <- findCorrelation(correlationMatrix, cutoff=0.7)


#Split data into training and test sets 

#TrainingDataIndex_m <- createDataPartition(numeric_df$Cluster, p=0.75, list = FALSE)
#training_samples_m <- numeric_df[TrainingDataIndex_m, -highlyCorrelated]
#test_samples_m <- numeric_df[-TrainingDataIndex_m, -highlyCorrelated]

# Save the indices to a file for future use
#saveRDS(TrainingDataIndex_m, file = "TrainingDataIndex_m.rds")

# Save the training and test data frames
#saveRDS(training_samples_m, file = "training_samples_m.rds")
#saveRDS(test_samples_m, file = "test_samples_m.rds")

# Load the saved partition indices
TrainingDataIndex_m <- readRDS("TrainingDataIndex_m_save.rds")
training_samples_m <- readRDS("training_samples_m_save.rds")
test_samples_m <- readRDS("test_samples_m_save.rds")


ngenes <- ncol(training_samples_m) - 2

dim(training_samples_m)
dim(test_samples_m)

#model controls 

set.seed(123)

ctrl <- trainControl(
  method = "repeatedcv",
  number = 15,
  repeats = 10,
  classProbs = T,
  savePredictions = T,
  summaryFunction = multiClassSummary,
  verboseIter = TRUE,
  allowParallel = TRUE
)

# Create valid variable names for class levels
training_samples_m$Cluster <- make.names(training_samples_m$Cluster)

rf.model_cv_m <- train(x = training_samples_m[1:ngenes],
                           y= training_samples_m$Cluster,
                           method = "ranger",
                           metric = "ROC",
                           importance= 'impurity',
                           trControl = ctrl,
                           num.trees = 750)

rf.model_cv_m <- readRDS("rf_model_cv_m4.rds")


#predictive power 

#get the predictions
rfcv_pred_m <- predict(rf.model_cv_m, test_samples_m[1:ngenes])

# Create valid variable names for class levels
test_samples_m$Cluster <- make.names(test_samples_m$Cluster)

# compare the predictins to the actual classifications
rfcv_cm_m <- caret::confusionMatrix(rfcv_pred_m, as.factor(test_samples_m$Cluster))

rfcv_cm_m




#LDA MODEL 
set.seed(123)


lda.model_m <- train(x = training_samples_m[1:ngenes],
                       y= training_samples_m$Cluster,
                       method = "lda",
                       metric = "ROC",
                       trControl = ctrl)

lda.model_m <- readRDS("lda_model_m_roc2.rds")


lda_pred_m <- predict(lda.model_m, test_samples_m[1:ngenes])
lda_pred_m <- factor(lda_pred_m, levels = levels(as.factor(test_samples_m$Cluster)))
lda_cm_m <- caret::confusionMatrix(lda_pred_m, as.factor(test_samples_m$Cluster))
# view confusion matrix
lda_cm_m


#KNN
set.seed(123)

knn.model_m <- train(x = training_samples_m[1:ngenes],
                         y= training_samples_m$Cluster,
                         method = "kknn",
                         metric = "ROC",
                         trControl = ctrl)

knn.model_m <- readRDS("knn_model_m_roc2.rds")

knn_pred_m <- predict(knn.model_m, test_samples_m[1:ngenes])
knn_cm_m <- caret::confusionMatrix(knn_pred_m, as.factor(test_samples_m$Cluster))
# view confusion matrix
knn_cm_m

#AUC 

# Extract predictions
rf_pred <- rf.model_cv_m$pred
lda_pred <- lda.model_m$pred
knn_pred <- knn.model_m$pred

# Assign model names
rf_pred$model <- "RF"
lda_pred$model <- "LDA"
knn_pred$model <- "KNN"

# Align column structures for each model's predictions
rf_pred_aligned <- rf_pred %>%
  select(pred, obs, X1:X6, rowIndex, Resample) %>%
  mutate(model = "RF")

lda_pred_aligned <- lda_pred %>%
  select(pred, obs, X1:X6, rowIndex, Resample) %>%
  mutate(model = "LDA")

knn_pred_aligned <- knn_pred %>%
  select(pred, obs, X1:X6, rowIndex, Resample) %>%
  mutate(model = "KNN")


# Combine aligned predictions
all_pred <- rbind(rf_pred_aligned, lda_pred_aligned, knn_pred_aligned)


# Plot ROC curves
g <- ggplot(all_pred, aes(m = X5, d = as.numeric(obs == "X5"), group = model, colour = model)) + 
  geom_roc(n.cuts = 0) + 
  style_roc()

print(g)

library(pROC)

# Calculate AUC for each model
rf_auc <- auc(as.numeric(rf_pred_aligned$obs == "X5"), rf_pred_aligned$X5)
lda_auc <- auc(as.numeric(lda_pred_aligned$obs == "X5"), lda_pred_aligned$X5)
knn_auc <- auc(as.numeric(knn_pred_aligned$obs == "X5"), knn_pred_aligned$X5)

aucs <- data.frame(
  model = c("RF", "LDA", "KNN"),
  AUC = c(rf_auc, lda_auc, knn_auc)
)

print(aucs)





#Gradiant boosting 
set.seed(123)
# Gradient Boosting Machines (GBM)
gbmGrid <- expand.grid(interaction.depth = c(1, 5, 9),
                       n.trees = c(100, 500, 1000),
                       shrinkage = c(0.01, 0.1),
                       n.minobsinnode = 10)

gbm.model_m <- train(x = training_samples_m[1:ngenes],
                     y = training_samples_m$Cluster,
                     method = "gbm",
                     metric = "ROC",
                     tuneGrid = gbmGrid,
                     trControl = ctrl,
                     verbose = FALSE)

# Predictive power
gbm_pred_m <- predict(gbm.model_m, test_samples_m[1:ngenes])
gbm_cm_m <- caret::confusionMatrix(gbm_pred_m, as.factor(test_samples_m$Cluster))
gbm_cm_m



# Support Vector Machines (SVM)
svmGrid <- expand.grid(C = c(0.1, 1, 10),
                       sigma = c(0.01, 0.05, 0.1))

svm.model_m <- train(x = training_samples_m[1:ngenes],
                     y = training_samples_m$Cluster,
                     method = "svmRadial",
                     metric = "ROC",
                     tuneGrid = svmGrid,
                     trControl = ctrl)

# Predictive power
svm_pred_m <- predict(svm.model_m, test_samples_m[1:ngenes])
svm_cm_m <- caret::confusionMatrix(svm_pred_m, as.factor(test_samples_m$Cluster))
svm_cm_m

# Extreme Gradient Boosting (XGBoost)
xgbGrid <- expand.grid(nrounds = c(100, 200),
                       max_depth = c(3, 6, 9),
                       eta = c(0.01, 0.1, 0.3),
                       gamma = 0,
                       colsample_bytree = 1,
                       min_child_weight = 1,
                       subsample = 1)

xgb.model_m <- train(x = training_samples_m[1:ngenes],
                     y = training_samples_m$Cluster,
                     method = "xgbTree",
                     metric = "ROC",
                     tuneGrid = xgbGrid,
                     trControl = ctrl)

# Predictive power
xgb_pred_m <- predict(xgb.model_m, test_samples_m[1:ngenes])
xgb_cm_m <- caret::confusionMatrix(xgb_pred_m, as.factor(test_samples_m$Cluster))
xgb_cm_m


# Neural Networks (NN)
nnGrid <- expand.grid(size = c(5, 10), decay = c(0.1, 0.5))

nn.model_m <- train(
  x = training_samples_m[1:ngenes],
  y = training_samples_m$Cluster,
  method = "nnet",
  metric = "ROC",
  tuneGrid = nnGrid,
  trControl = ctrl,
  linout = FALSE
)



#Try and improve Rf and lda 

library(caret)
library(MASS)

set.seed(123)


# Define the train control with k-fold cross-validation
train_control <- trainControl(method = "cv", number = 5)

# Train the LDA model using cross-validation
lda_model <- train(training_samples_m[1:ngenes], training_samples_m$Cluster, method = "lda", trControl = train_control)

# Print the results
print(lda_model)


# Train the LDA model with different shrinkage values
lda_grid <- expand.grid(.lambda = c(0, 0.1, 0.5, 0.9))

lda_model_shrink <- train(training_samples_m[1:ngenes], training_samples_m$Cluster, method = "lda2", trControl = train_control, tuneGrid = lda_grid)

# Print the best model
print(lda_model_shrink)


library(ada)

# Train an AdaBoost model with LDA as the base learner
ada_model <- train(training_samples_m[1:ngenes], training_samples_m$Cluster, method = "ada", trControl = train_control, tuneGrid = data.frame(mfinal=100))

# Print the results
print(ada_model)




set.seed(123)

ctrl <- trainControl(
  method = "repeatedcv",
  number = 15,
  repeats = 10,
  classProbs = T,
  savePredictions = T,
  summaryFunction = multiClassSummary,
  verboseIter = TRUE,
  allowParallel = TRUE
)

# Create valid variable names for class levels
training_samples_m$Cluster <- make.names(training_samples_m$Cluster)

rf.model_cv_m1 <- train(x = training_samples_m[1:ngenes],
                        y= training_samples_m$Cluster,
                        method = "ranger",
                        metric = "ROC",
                        importance= 'impurity',
                        trControl = ctrl,
                        num.trees = 750)

rf.model_cv_m1

# Save the model to a file
saveRDS(rf.model_cv_m1, file = "rf_model_cv_m1.rds")


rf.model_cv_m1 <- readRDS("rf_model_cv_m1.rds")


#get the predictions
rfcv_pred_m1 <- predict(rf.model_cv_m1, test_samples_m[1:ngenes])

# Create valid variable names for class levels
test_samples_m$Cluster <- make.names(test_samples_m$Cluster)

# compare the predictins to the actual classifications
rfcv_cm_m1 <- caret::confusionMatrix(rfcv_pred_m1, as.factor(test_samples_m$Cluster))

rfcv_cm_m1



set.seed(123)

ctrl <- trainControl(
  method = "repeatedcv",
  number = 15,
  repeats = 15,
  classProbs = T,
  savePredictions = T,
  summaryFunction = multiClassSummary,
  verboseIter = TRUE,
  allowParallel = TRUE
)

# Create valid variable names for class levels
training_samples_m$Cluster <- make.names(training_samples_m$Cluster)

rf.model_cv_m2 <- train(x = training_samples_m[1:ngenes],
                        y= training_samples_m$Cluster,
                        method = "ranger",
                        metric = "ROC",
                        importance= 'impurity',
                        trControl = ctrl,
                        num.trees = 1000)

rf.model_cv_m2


# Save the model to a file
saveRDS(rf.model_cv_m2, file = "rf_model_cv_m2.rds")


rf.model_cv_m2 <- readRDS("rf_model_cv_m2.rds")


#get the predictions
rfcv_pred_m2 <- predict(rf.model_cv_m2, test_samples_m[1:ngenes])

# Create valid variable names for class levels
test_samples_m$Cluster <- make.names(test_samples_m$Cluster)

# compare the predictins to the actual classifications
rfcv_cm_m2 <- caret::confusionMatrix(rfcv_pred_m2, as.factor(test_samples_m$Cluster))

rfcv_cm_m2


rf.model_cv_m3 <- readRDS("rf_model_cv_m3.rds")


#get the predictions
rfcv_pred_m3 <- predict(rf.model_cv_m3, test_samples_m[1:ngenes])

# Create valid variable names for class levels
test_samples_m$Cluster <- make.names(test_samples_m$Cluster)

# compare the predictins to the actual classifications
rfcv_cm_m3 <- caret::confusionMatrix(rfcv_pred_m3, as.factor(test_samples_m$Cluster))

rfcv_cm_m3


